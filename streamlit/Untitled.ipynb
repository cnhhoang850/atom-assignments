{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bbeb3f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channel ID: C01B4PVGLVB - Channel Name: general\n",
      "Channel ID: C01BYH7JHB5 - Channel Name: contents\n",
      "====> {'ok': False, 'error': 'not_in_channel'}\n",
      "Channel ID: C01CAMNCJJV - Channel Name: branding-design\n",
      "Channel ID: C01U6P7LZ8F - Channel Name: atom-assignment1\n",
      "Channel ID: C01UL6K1C7L - Channel Name: atom-week1\n",
      "Channel ID: C01ULCHGN75 - Channel Name: atom-general\n",
      "====> {'ok': False, 'error': 'not_in_channel'}\n",
      "Channel ID: C020VMT58JK - Channel Name: topics-data-analytics\n",
      "Channel ID: C0213MNH9L6 - Channel Name: topics-python\n",
      "Channel ID: C0213N56M2A - Channel Name: topics-materials\n",
      "Channel ID: C021FSDN7LJ - Channel Name: atom-assignment2\n",
      "Channel ID: C021KLB0DSB - Channel Name: discuss-group3\n",
      "Channel ID: C021KLB90GP - Channel Name: discuss-group4\n",
      "Channel ID: C02204B2CD6 - Channel Name: atom-week2\n",
      "Channel ID: C0220KU9399 - Channel Name: discuss-group1\n",
      "Channel ID: C0226D3LEQ4 - Channel Name: atom-week3\n",
      "Channel ID: C0227A51SAY - Channel Name: atom-assignment3\n",
      "Channel ID: C022Q7TGRLG - Channel Name: discuss-group2\n",
      "Channel ID: C022RRWQ6US - Channel Name: atom-assignment4\n",
      "Channel ID: C022Y1FUETE - Channel Name: atom-week4\n",
      "Channel ID: C023UJGMDND - Channel Name: atom-assignment5\n",
      "Channel ID: C0245PZUFSL - Channel Name: atom-week5\n",
      "Channel ID: C024B4980DA - Channel Name: atom-week6\n",
      "Channel ID: C024UNTHPB2 - Channel Name: atom-assignment6\n",
      "Channel ID: C024W7TKYLT - Channel Name: atom-week7\n",
      "Channel ID: C02526A3DS8 - Channel Name: atom-assignment7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-13 13:30:46.043 INFO    numexpr.utils: NumExpr defaulting to 4 threads.\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import json\n",
    "import requests\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from datetime import datetime as dt\n",
    "\n",
    "\n",
    "with open('./env_variables.json','r') as j:\n",
    "    json_data = json.load(j)\n",
    "\n",
    "#SLACK_BEARER_TOKEN = os.environ.get('SLACK_BEARER_TOKEN') ## Get in setting of Streamlit Share\n",
    "SLACK_BEARER_TOKEN = json_data['SLACK_BEARER_TOKEN']\n",
    "DTC_GROUPS_URL = ('https://raw.githubusercontent.com/anhdanggit/atom-assignments/main/data/datacracy_groups.csv')\n",
    "#st.write(json_data['SLACK_BEARER_TOKEN'])\n",
    "\n",
    "def load_users_df():\n",
    "    # Slack API User Data\n",
    "    endpoint = \"https://slack.com/api/users.list\"\n",
    "    headers = {\"Authorization\": \"Bearer {}\".format(json_data['SLACK_BEARER_TOKEN'])}\n",
    "    response_json = requests.post(endpoint, headers=headers).json() \n",
    "    user_dat = response_json['members']\n",
    "\n",
    "    # Convert to CSV\n",
    "    user_dict = {'user_id':[],'name':[],'display_name':[],'real_name':[],'title':[],'is_bot':[]}\n",
    "    for i in range(len(user_dat)):\n",
    "      user_dict['user_id'].append(user_dat[i]['id'])\n",
    "      user_dict['name'].append(user_dat[i]['name'])\n",
    "      user_dict['display_name'].append(user_dat[i]['profile']['display_name'])\n",
    "      user_dict['real_name'].append(user_dat[i]['profile']['real_name_normalized'])\n",
    "      user_dict['title'].append(user_dat[i]['profile']['title'])\n",
    "      user_dict['is_bot'].append(int(user_dat[i]['is_bot']))\n",
    "    user_df = pd.DataFrame(user_dict) \n",
    "    # Read dtc_group hosted in github\n",
    "    dtc_groups = pd.read_csv(DTC_GROUPS_URL)\n",
    "    user_df = user_df.merge(dtc_groups, how='left', on='name')\n",
    "    return user_df\n",
    "\n",
    "def load_channel_df():\n",
    "    endpoint2 = \"https://slack.com/api/conversations.list\"\n",
    "    data = {'types': 'public_channel,private_channel'} # -> CHECK: API Docs https://api.slack.com/methods/conversations.list/test\n",
    "    headers = {\"Authorization\": \"Bearer {}\".format(SLACK_BEARER_TOKEN)}\n",
    "    response_json = requests.post(endpoint2, headers=headers, data=data).json() \n",
    "    channel_dat = response_json['channels']\n",
    "    channel_dict = {'channel_id':[], 'channel_name':[], 'is_channel':[],'creator':[],'created_at':[],'topics':[],'purpose':[],'num_members':[]}\n",
    "    for i in range(len(channel_dat)):\n",
    "        channel_dict['channel_id'].append(channel_dat[i]['id'])\n",
    "        channel_dict['channel_name'].append(channel_dat[i]['name'])\n",
    "        channel_dict['is_channel'].append(channel_dat[i]['is_channel'])\n",
    "        channel_dict['creator'].append(channel_dat[i]['creator'])\n",
    "        channel_dict['created_at'].append(dt.fromtimestamp(float(channel_dat[i]['created'])))\n",
    "        channel_dict['topics'].append(channel_dat[i]['topic']['value'])\n",
    "        channel_dict['purpose'].append(channel_dat[i]['purpose']['value'])\n",
    "        channel_dict['num_members'].append(channel_dat[i]['num_members'])\n",
    "    channel_df = pd.DataFrame(channel_dict) \n",
    "    return channel_df\n",
    "\n",
    "def load_msg_dict():\n",
    "    endpoint3 = \"https://slack.com/api/conversations.history\"\n",
    "    headers = {\"Authorization\": \"Bearer {}\".format(SLACK_BEARER_TOKEN)}\n",
    "    msg_dict = {'channel_id':[],'msg_id':[], 'msg_ts':[], 'user_id':[], 'latest_reply':[],'reply_user_count':[],'reply_users':[],'github_link':[],'text':[]}\n",
    "    for channel_id, channel_name in zip(channel_df['channel_id'], channel_df['channel_name']):\n",
    "        print('Channel ID: {} - Channel Name: {}'.format(channel_id, channel_name))\n",
    "        try:\n",
    "            data = {\"channel\": channel_id} \n",
    "            response_json = requests.post(endpoint3, data=data, headers=headers).json()\n",
    "            msg_ls = response_json['messages']\n",
    "            for i in range(len(msg_ls)):\n",
    "                if 'client_msg_id' in msg_ls[i].keys():\n",
    "                    msg_dict['channel_id'].append(channel_id)\n",
    "                    msg_dict['msg_id'].append(msg_ls[i]['client_msg_id'])\n",
    "                    msg_dict['msg_ts'].append(dt.fromtimestamp(float(msg_ls[i]['ts'])))\n",
    "                    msg_dict['latest_reply'].append(dt.fromtimestamp(float(msg_ls[i]['latest_reply'] if 'latest_reply' in msg_ls[i].keys() else 0))) ## -> No reply: 1970-01-01\n",
    "                    msg_dict['user_id'].append(msg_ls[i]['user'])\n",
    "                    msg_dict['reply_user_count'].append(msg_ls[i]['reply_users_count'] if 'reply_users_count' in msg_ls[i].keys() else 0)\n",
    "                    msg_dict['reply_users'].append(msg_ls[i]['reply_users'] if 'reply_users' in msg_ls[i].keys() else 0) \n",
    "                    msg_dict['text'].append(msg_ls[i]['text'] if 'text' in msg_ls[i].keys() else 0) \n",
    "                    ## -> Censor message contains tokens\n",
    "                    text = msg_ls[i]['text']\n",
    "                    github_link = re.findall('(?:https?://)?(?:www[.])?github[.]com/[\\w-]+/?', text)\n",
    "                    msg_dict['github_link'].append(github_link[0] if len(github_link) > 0 else None)\n",
    "        except:\n",
    "            print('====> '+ str(response_json))\n",
    "    msg_df = pd.DataFrame(msg_dict)\n",
    "    return msg_df\n",
    "\n",
    "def process_msg_data(msg_df, user_df, channel_df):\n",
    "    ## Merge to have a nice name displayed\n",
    "    msg_df = msg_df.merge(user_df[['user_id','name','DataCracy_role']].rename(columns={'name':'submit_name'}), \\\n",
    "        how='left',on='user_id')\n",
    "    ## Merge for nice channel name\n",
    "    msg_df = msg_df.merge(channel_df[['channel_id','channel_name','created_at']], how='left',on='channel_id')\n",
    "    ## Format datetime cols\n",
    "    msg_df['created_at'] = msg_df['created_at'].dt.strftime('%Y-%m-%d')\n",
    "    msg_df['msg_date'] = msg_df['msg_ts'].dt.strftime('%Y-%m-%d')\n",
    "    msg_df['msg_time'] = msg_df['msg_ts'].dt.strftime('%H:%M')\n",
    "    msg_df['wordcount'] = msg_df.text.apply(lambda s: len(s.split()))\n",
    "    \n",
    "    msg_df = msg_df.dropna(subset=['channel_name'])\n",
    "    return msg_df\n",
    "\n",
    "\n",
    "# Table data\n",
    "user_df = load_users_df()\n",
    "channel_df = load_channel_df()\n",
    "msg_df = load_msg_dict()\n",
    "\n",
    "#st.write(process_msg_data(msg_df, user_df, channel_df))\n",
    "\n",
    "\n",
    "# Input\n",
    "st.sidebar.markdown('## Thông tin')\n",
    "user_id = st.sidebar.text_input(\"Nhập Mã Số Người Dùng\", 'U01xxxx')\n",
    "\n",
    "user_df = user_df[user_df['DataCracy_role'].str.contains('Learner', na=False)]\t\n",
    "user_cols = ['user_id', 'name', 'DataCracy_role']\n",
    "channel_df = channel_df[channel_df['channel_name'].str.contains('assignment', na=False)]\n",
    "\n",
    "p_msg_df = process_msg_data(msg_df, user_df, channel_df)\n",
    "\n",
    "submit_df = p_msg_df[p_msg_df.channel_name.str.contains('assignment', na=False)]\n",
    "\n",
    "submit_df = submit_df[submit_df.DataCracy_role.str.contains('Learner', na=False)]\n",
    "latest_ts = submit_df.groupby(['channel_name', 'user_id']).msg_ts.idxmax() ## -> Latest ts\n",
    "submit_df = submit_df.loc[latest_ts]\n",
    "submit_df = submit_df.rename(columns={'channel_name':'assignment'})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dis_cols1 = ['assignment','msg_date','msg_time','reply_user_count', 'submit_name']\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4edb1c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['not-late', 'late', 'not-late', 'not-late', 'late', 'not-late', 'not-late', 'not-late', 'not-late', 'not-late', 'not-late', 'not-late', 'not-late', 'late', 'late', 'late', 'late', 'not-late', 'not-late', 'late', 'late', 'not-late', 'late', 'not-late', 'not-late', 'late', 'not-late', 'late', 'not-late', 'not-late', 'not-late', 'not-late', 'not-late', 'late', 'late', 'not-late', 'not-late', 'not-late', 'not-late', 'not-late', 'not-late', 'not-late', 'not-late', 'not-late', 'not-late', 'not-late', 'not-late', 'not-late', 'not-late', 'not-late', 'late', 'not-late', 'late', 'late', 'not-late', 'not-late', 'not-late', 'not-late', 'not-late', 'late', 'not-late', 'not-late', 'not-late', 'not-late', 'late', 'late', 'not-late', 'not-late', 'not-late', 'not-late', 'late', 'not-late', 'late', 'not-late', 'not-late', 'late', 'not-late', 'not-late', 'not-late', 'not-late', 'late', 'late', 'not-late', 'not-late', 'not-late', 'not-late', 'not-late', 'not-late', 'not-late', 'not-late', 'not-late', 'late', 'late', 'late', 'not-late', 'not-late', 'late', 'late', 'not-late', 'not-late', 'late', 'not-late', 'not-late', 'not-late', 'not-late', 'not-late', 'late', 'late', 'not-late', 'not-late', 'not-late', 'late', 'not-late', 'not-late', 'not-late', 'not-late', 'late', 'late', 'not-late', 'late', 'not-late', 'late', 'not-late', 'not-late', 'not-late', 'not-late', 'not-late', 'late', 'late', 'late', 'not-late', 'not-late', 'not-late', 'not-late', 'not-late', 'not-late', 'not-late', 'not-late', 'not-late', 'not-late', 'not-late', 'not-late', 'late', 'not-late', 'not-late', 'not-late', 'late', 'not-late']\n"
     ]
    }
   ],
   "source": [
    "deadlines = {\n",
    "    \"assignment1\": '2021-04-24',\n",
    "    \"assignment2\": '2021-05-15',\n",
    "    \"assignment3\": '2021-05-22',\n",
    "    \"assignment4\": '2021-05-29',\n",
    "    \"assignment5\": '2021-06-05',\n",
    "    \"assignment6\": '2021-06-12'\n",
    "}\n",
    "status = []\n",
    "\n",
    "for i in range(len(submit_df)):\n",
    "    learner = submit_df.iloc[i]['msg_date']\n",
    "    deadline = deadlines[submit_df.iloc[i]['assignment'][5:]]\n",
    "    if learner > deadline: \n",
    "        status.append('late')\n",
    "    else: \n",
    "        status.append('not-late')\n",
    "\n",
    "print(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11961083",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
